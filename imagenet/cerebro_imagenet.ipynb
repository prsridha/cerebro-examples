{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebro.etl.etl_spec import ETLSpec\n",
    "from cerebro.experiment import Experiment\n",
    "from cerebro.mop.sub_epoch_spec import SubEpochSpec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetETLSpec(ETLSpec):\n",
    "    def __init__(self):\n",
    "        self.is_feature_download = [False, False, True, False, False]\n",
    "        \n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "    \n",
    "    def row_preprocessor(self, row, mode, object_dir):\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "\n",
    "        input_image_path = object_dir + \"/\" + str(row[\"filepath\"])\n",
    "\n",
    "        pil_image = Image.open(input_image_path)\n",
    "        image = np.asarray(pil_image.convert('RGB').resize((112, 112)))\n",
    "        image = image / 255.0\n",
    "        image = image - [0.485, 0.456, 0.406]\n",
    "        image = image / [0.229, 0.224, 0.225]\n",
    "\n",
    "        torch_image = torch.from_numpy(image).float()\n",
    "        image = torch.reshape(torch_image, (torch_image.shape[2], torch_image.shape[0], torch_image.shape[1]))\n",
    "        if mode == 'test':\n",
    "            return image, None\n",
    "        else:\n",
    "            label = torch.tensor(row[\"label\"])\n",
    "            return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTrainingSpec(SubEpochSpec):\n",
    "    def __init__(self):\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "        self.log_softmax = torch.nn.LogSoftmax().cuda() if torch.cuda.is_available() else torch.nn.LogSoftmax()\n",
    "\n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "\n",
    "    def accuracy(self, output, target, topk=(1, ), binary=False):\n",
    "        import torch\n",
    "\n",
    "        \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "        if binary:\n",
    "            batch_size = target.size(0)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct = (pred == target).sum().item()\n",
    "            res = [torch.tensor(correct / batch_size)]\n",
    "        else:\n",
    "            maxk = max(topk)\n",
    "            maxk = min(maxk, output.shape[1])\n",
    "            batch_size = target.size(0)\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "            res = []\n",
    "            for k in topk:\n",
    "                correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "                res.append(correct_k.mul_(1.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "    def train(self, parallelize, save_checkpoint, model_file, train_loader, hyperparams, device, logger):\n",
    "        import os\n",
    "        import math\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        from torchvision import models\n",
    "\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "        learning_rate = hyperparams[\"learning_rate\"]\n",
    "        lambda_value = hyperparams[\"lambda_value\"]\n",
    "        model_type = hyperparams[\"model_type\"]\n",
    "        train_results = {\n",
    "            \"stats\": [],\n",
    "            \"additive_metrics\": {}\n",
    "        }\n",
    "\n",
    "        if model_type == \"resnet50\":\n",
    "            model = models.resnet50(pretrained=False)\n",
    "        elif model_type == \"vgg16\":\n",
    "            model = models.vgg16(pretrained=False)\n",
    "        model = model.to(device)\n",
    "        model = parallelize(model)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                         lr=learning_rate,\n",
    "                                         weight_decay=lambda_value)\n",
    "        \n",
    "        if os.path.isfile(model_file):\n",
    "            checkpoint = torch.load(model_file)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        i_step = 0\n",
    "        total_subepoch_loss = 0\n",
    "        total_subepoch_top_1_acc = 0\n",
    "        total_subepoch_top_5_acc = 0\n",
    "        subepoch_total_step = math.ceil(len(train_loader.dataset) / batch_size)\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch[0].to(device), torch.tensor(batch[1]).to(device)\n",
    "            optimizer.zero_grad()\n",
    "                        \n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            outputs_softmax = self.log_softmax(outputs)\n",
    "            \n",
    "            top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "            \n",
    "            subepoch_loss = loss.item()\n",
    "            subepoch_top_1_acc = top_1_acc.item()\n",
    "            subepoch_top_5_acc = top_5_acc.item()\n",
    "\n",
    "            total_subepoch_loss += subepoch_loss\n",
    "            total_subepoch_top_1_acc += subepoch_top_1_acc\n",
    "            total_subepoch_top_5_acc += subepoch_top_5_acc\n",
    "\n",
    "            stats_dict = {\n",
    "                \"subepoch_loss\": subepoch_loss,\n",
    "                \"subepoch_top_1_acc\": subepoch_top_1_acc,\n",
    "                \"subepoch_top_5_acc\": subepoch_top_5_acc\n",
    "            }\n",
    "\n",
    "            stats = \"Train step [%d/%d], subepoch_loss: %.4f, subepoch_top_1_acc: %5.4f, , subepoch_top_5_acc: %5.4f\" \\\n",
    "                        % (i_step, subepoch_total_step,subepoch_loss, \n",
    "                           subepoch_top_1_acc, subepoch_top_5_acc)\n",
    "\n",
    "            print(\"\\r\" + stats, end=\"\")\n",
    "\n",
    "            train_results[\"stats\"].append(stats_dict)\n",
    "\n",
    "            i_step += 1\n",
    "\n",
    "        train_results[\"additive_metrics\"] = {\n",
    "            \"total_subepoch_loss\": total_subepoch_loss,\n",
    "            \"total_subepoch_top_1_acc\": total_subepoch_top_1_acc,\n",
    "            \"total_subepoch_top_5_acc\": total_subepoch_top_5_acc\n",
    "        }\n",
    "    \n",
    "        logger(train_results)\n",
    "\n",
    "        save_checkpoint({\"model\": model.state_dict(),\n",
    "                    \"optimizer\" : optimizer.state_dict()\n",
    "                   })\n",
    "    \n",
    "    def test(self, parallelize, save_checkpoint, model_file, test_loader, hyperparams, device, logger):\n",
    "        import os\n",
    "        import math\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        from torchvision import models\n",
    "\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "        model_type = hyperparams[\"model_type\"]\n",
    "        test_results = {\n",
    "            \"stats\": []\n",
    "        }\n",
    "\n",
    "        if model_type == \"resnet50\":\n",
    "            model = models.resnet50(pretrained=False)\n",
    "        elif model_type == \"vgg16\":\n",
    "            model = models.vgg16(pretrained=False)\n",
    "        model = model.to(device)\n",
    "        model = parallelize(model)\n",
    "\n",
    "        if os.path.isfile(model_file):\n",
    "            checkpoint = torch.load(model_file)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_top_1_acc = 0.0\n",
    "        epoch_top_5_acc = 0.0\n",
    "        subepoch_total_step = math.ceil(len(test_loader.dataset) / batch_size)\n",
    "        \n",
    "        batch_num = 1\n",
    "        with torch.no_grad():    \n",
    "            for batch in test_loader:\n",
    "                images, labels = batch[0].to(device), torch.tensor(batch[1]).to(device)\n",
    "                outputs = model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                outputs_softmax = self.log_softmax(outputs)\n",
    "                top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "\n",
    "                epoch_loss += (loss.item() / batch_num )\n",
    "                epoch_top_1_acc += (top_1_acc.item() / batch_num)\n",
    "                epoch_top_5_acc += (top_5_acc.item() / batch_num)\n",
    "            \n",
    "                batch_num += 1\n",
    "\n",
    "                stats = \"Test step [%d/%d], loss: %.4f, top_1_acc: %5.4f, , top_5_acc: %5.4f\" \\\n",
    "                            % (batch_num, subepoch_total_step,epoch_loss, \n",
    "                            epoch_top_1_acc, epoch_top_5_acc)\n",
    "\n",
    "            print(\"\\r\" + stats, end=\"\")\n",
    "\n",
    "        test_results[\"stats\"] = {\n",
    "            \"total_epoch_loss\": epoch_loss,\n",
    "            \"total_epoch_top_1_acc\": epoch_top_1_acc,\n",
    "            \"total_epoch_top_5_acc\": epoch_top_5_acc\n",
    "        }\n",
    "    \n",
    "        logger(test_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Model Building specifications </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "param_grid = {\n",
    "    'batch_size': [128, 256],\n",
    "    'learning_rate': [1e-2, 1e-3],\n",
    "    'lambda_value': [1e-3, 1e-4],\n",
    "    'model_type': ['vgg16', 'resnet50']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Initialize Experiment </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment()\n",
    "etl_spec = ImagenetETLSpec()\n",
    "sub_epoch_spec = ImagenetTrainingSpec()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_etl(etl_spec, fraction=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_fit(sub_epoch_spec, param_grid, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
