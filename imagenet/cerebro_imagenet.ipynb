{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebro.etl.etl_spec import ETLSpec\n",
    "from cerebro.experiment import Experiment\n",
    "from cerebro.mop.sub_epoch_spec import SubEpochSpec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetETLSpec(ETLSpec):\n",
    "    def __init__(self):\n",
    "        self.is_feature_download = [False, False, True, False, False]\n",
    "        \n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "    \n",
    "    def row_preprocessor(self, row, mode, object_dir):\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "\n",
    "        input_image_path = object_dir + \"/\" + str(row[\"filepath\"])\n",
    "\n",
    "        pil_image = Image.open(input_image_path)\n",
    "        image = np.asarray(pil_image.convert('RGB').resize((112, 112)))\n",
    "        image = image / 255.0\n",
    "        image = image - [0.485, 0.456, 0.406]\n",
    "        image = image / [0.229, 0.224, 0.225]\n",
    "\n",
    "        torch_image = torch.from_numpy(image).float()\n",
    "        image = torch.reshape(torch_image, (torch_image.shape[2], torch_image.shape[0], torch_image.shape[1]))\n",
    "        if mode == 'test':\n",
    "            return image, None\n",
    "        else:\n",
    "            label = torch.tensor(row[\"label\"])\n",
    "            return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTrainingSpec(SubEpochSpec):\n",
    "    def __init__(self):\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "        self.log_softmax = torch.nn.LogSoftmax().cuda() if torch.cuda.is_available() else torch.nn.LogSoftmax()\n",
    "\n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "\n",
    "    def create_model_components(self, hyperparams):\n",
    "        import torch\n",
    "        from torchvision import models\n",
    "\n",
    "        learning_rate = hyperparams[\"learning_rate\"]\n",
    "        lambda_value = hyperparams[\"lambda_value\"]\n",
    "        model_type = hyperparams[\"model_type\"]\n",
    "\n",
    "        if model_type == \"resnet50\":\n",
    "            model = models.resnet50(pretrained=False)\n",
    "        elif model_type == \"vgg16\":\n",
    "            model = models.vgg16(pretrained=False)\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                         lr=learning_rate,\n",
    "                                         weight_decay=lambda_value)\n",
    "        \n",
    "        model_object = {\n",
    "            \"imagenet_model\": model,\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "\n",
    "        return model_object\n",
    "\n",
    "    def accuracy(self, output, target, topk=(1, ), binary=False):\n",
    "        import torch\n",
    "\n",
    "        \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "        if binary:\n",
    "            batch_size = target.size(0)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct = (pred == target).sum().item()\n",
    "            res = [torch.tensor(correct / batch_size)]\n",
    "        else:\n",
    "            maxk = max(topk)\n",
    "            maxk = min(maxk, output.shape[1])\n",
    "            batch_size = target.size(0)\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "            res = []\n",
    "            for k in topk:\n",
    "                correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "                res.append(correct_k.mul_(1.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "    def train(self, model_object, dataloader, hyperparams, input_device, output_device):\n",
    "        import math\n",
    "        import torch\n",
    "\n",
    "        train_metrics = []\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "\n",
    "        obj = model_object(\"load\")\n",
    "        model = obj[\"imagenet_model\"]\n",
    "        optimizer = obj[\"optimizer\"]\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        i_step = 0\n",
    "        subepoch_total_step = math.ceil(len(dataloader.dataset) / batch_size)\n",
    "\n",
    "        for batch in dataloader:\n",
    "            images, labels = batch[0].to(input_device), torch.tensor(batch[1]).to(output_device)\n",
    "            outputs = model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs_softmax = self.log_softmax(outputs)\n",
    "            \n",
    "            top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "            \n",
    "            subepoch_loss = loss.item() / batch_size\n",
    "            subepoch_top_1_acc = top_1_acc.item()\n",
    "            subepoch_top_5_acc = top_5_acc.item()\n",
    "\n",
    "            stats_dict = {\n",
    "                \"subepoch_loss\": subepoch_loss,\n",
    "                \"subepoch_top_1_acc\": subepoch_top_1_acc,\n",
    "                \"subepoch_top_5_acc\": subepoch_top_5_acc\n",
    "            }\n",
    "\n",
    "            stats = \"Train step [%d/%d], subepoch_loss: %.4f, subepoch_top_1_acc: %5.4f, , subepoch_top_5_acc: %5.4f\" \\\n",
    "                        % (i_step, subepoch_total_step,subepoch_loss, \n",
    "                           subepoch_top_1_acc, subepoch_top_5_acc)\n",
    "\n",
    "            print(\"\\r\" + stats, end=\"\")\n",
    "\n",
    "            train_metrics.append(stats_dict)\n",
    "\n",
    "            i_step += 1\n",
    "\n",
    "        model_object(\"save\", {\n",
    "                    \"imagenet_model\": model,\n",
    "                    \"optimizer\" : optimizer\n",
    "                   })\n",
    "        return train_metrics\n",
    "    \n",
    "    def val(self, model_object, dataloader, hyperparams, input_device, output_device):\n",
    "        import math\n",
    "        import torch\n",
    "\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "\n",
    "        obj = model_object(\"load\")\n",
    "        model = obj[\"imagenet_model\"]\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_top_1_acc = 0.0\n",
    "        epoch_top_5_acc = 0.0\n",
    "        subepoch_total_step = math.ceil(len(dataloader.dataset) / batch_size)\n",
    "        \n",
    "        batch_num = 1\n",
    "        with torch.no_grad():    \n",
    "            for batch in dataloader:\n",
    "                images, labels = batch[0].to(input_device), torch.tensor(batch[1]).to(output_device)\n",
    "                outputs = model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                outputs_softmax = self.log_softmax(outputs)\n",
    "                top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "\n",
    "                epoch_loss += (loss.item() / batch_num )\n",
    "                epoch_top_1_acc += (top_1_acc.item() / batch_num)\n",
    "                epoch_top_5_acc += (top_5_acc.item() / batch_num)\n",
    "            \n",
    "                batch_num += 1\n",
    "\n",
    "                stats = \"Validation step [%d/%d], loss: %.4f, top_1_acc: %5.4f, , top_5_acc: %5.4f\" \\\n",
    "                            % (batch_num, subepoch_total_step,epoch_loss, \n",
    "                            epoch_top_1_acc, epoch_top_5_acc)\n",
    "\n",
    "            print(\"\\r\" + stats, end=\"\")\n",
    "\n",
    "        val_metrics = {\n",
    "            \"total_epoch_loss\": epoch_loss,\n",
    "            \"total_epoch_top_1_acc\": epoch_top_1_acc,\n",
    "            \"total_epoch_top_5_acc\": epoch_top_5_acc\n",
    "        }\n",
    "    \n",
    "        return val_metrics\n",
    "    \n",
    "    def predict(self, model_object, dataloader, hyperparams, input_device):\n",
    "        import math\n",
    "        import torch\n",
    "\n",
    "        predictions = []\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "\n",
    "        obj = model_object(\"load\")\n",
    "        model = obj[\"imagenet_model\"]\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        subepoch_total_step = math.ceil(len(dataloader.dataset) / batch_size)\n",
    "        \n",
    "        batch_num = 1\n",
    "        with torch.no_grad():    \n",
    "            for batch in dataloader:\n",
    "                images = batch[0].to(input_device)\n",
    "                outputs = model(images)\n",
    "                outputs_softmax = self.log_softmax(outputs)\n",
    "                predictions.append(outputs_softmax)\n",
    "\n",
    "                batch_num += 1\n",
    "\n",
    "                stats = \"Test step [%d/%d]\" \\\n",
    "                            % (batch_num, subepoch_total_step)\n",
    "\n",
    "            print(\"\\r\" + stats, end=\"\")\n",
    "    \n",
    "        return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Model Building specifications </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "param_grid = {\n",
    "    'batch_size': [128, 256],\n",
    "    'learning_rate': [1e-2, 1e-3],\n",
    "    'lambda_value': [1e-3, 1e-4],\n",
    "    'model_type': ['vgg16', 'resnet50']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Initialize Experiment </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment()\n",
    "imagenet_etl_spec = ImagenetETLSpec()\n",
    "imagenet_training_spec = ImagenetTrainingSpec()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_etl(imagenet_etl_spec, fraction=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_fit(imagenet_training_spec, param_grid, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
